{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a7e460776549b7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:49:13.259813400Z",
     "start_time": "2024-12-05T23:49:13.241245300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import netCDF4\n",
    "import xarray as xr\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from scipy.interpolate import griddata\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import cftime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.models import Model, load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd69585-fb1e-4610-8073-1af42db8f2e8",
   "metadata": {},
   "source": [
    "## Static vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95d87a27-a83d-4a8d-8e92-036e480d8014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C%s08', 'C%s09', 'C%s10', 'C%s13']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GOESCH08_64_downsample.weights.h5',\n",
       " 'GOESCH09_64_downsample.weights.h5',\n",
       " 'GOESCH10_64_downsample.weights.h5',\n",
       " 'GOESCH13_64_downsample.weights.h5',\n",
       " 'IMERG_64_downsample_log.weights.h5']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peps = 1e-4 #epsilon in mm/h for IMERG log-normalization\n",
    "\n",
    "IMROOT = '/glade/work/jpan/IMERG_vecs/'\n",
    "GOROOT = '/glade/work/jpan/GOES_vecs/'\n",
    "WTROOT = './' #weights folder\n",
    "\n",
    "CHS = ['C%s' + num for num in ['08', '09', '10', '13']]\n",
    "print(CHS)\n",
    "\n",
    "LD = 64 #latent dim of autoencs\n",
    "INDIM = [97714, 97714, 97714, 97714, 39125]\n",
    "WTF = ['*' + ch % 'H' + '*.h5' for ch in CHS] + ['IMERG*.h5']\n",
    "WTF = [glob.glob(fn)[0] for fn in WTF]\n",
    "WTF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a36de-fa2b-4b4c-850f-4b6e28708a2c",
   "metadata": {},
   "source": [
    "## Open input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cf5c2b-bd59-4c42-b952-df0cf094a31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 10GB\n",
      "Dimensions:   (time: 26142, len: 97714)\n",
      "Coordinates:\n",
      "  * time      (time) object 209kB 2018-01-01 00:11:20 ... 2018-09-30 23:56:18\n",
      "  * len       (len) int64 782kB 0 1 2 3 4 5 ... 97709 97710 97711 97712 97713\n",
      "Data variables:\n",
      "    rad_vecs  (time, len) float32 10GB dask.array<chunksize=(2904, 97714), meta=np.ndarray>\n",
      "Attributes:\n",
      "    description:  ABI radiance vectors\n",
      "<xarray.Dataset> Size: 6GB\n",
      "Dimensions:  (time: 13104, idx: 39125)\n",
      "Coordinates:\n",
      "  * time     (time) object 105kB 2018-01-01 00:00:00 ... 2018-09-30 23:30:00\n",
      "  * idx      (idx) int64 313kB 0 1 2 3 4 5 ... 39120 39121 39122 39123 39124\n",
      "Data variables:\n",
      "    pmmhr    (time, idx) float32 2GB dask.array<chunksize=(1488, 39125), meta=np.ndarray>\n",
      "    lat      (time, idx) float32 2GB dask.array<chunksize=(1488, 39125), meta=np.ndarray>\n",
      "    lon      (time, idx) float32 2GB dask.array<chunksize=(1488, 39125), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "#GOES_dss = [netCDF4.MFDataset(os.path.join(GOROOT, ch % '' + '*.nc'), aggdim='time') for ch in CHS]\n",
    "GOES_dss = [xr.open_mfdataset(os.path.join(GOROOT, ch % '' + '*.nc'), combine='nested', concat_dim='time') for ch in CHS] #list of xr datasets\n",
    "for ii, gd in enumerate(GOES_dss):\n",
    "    #gd['time'] = pd.to_datetime(gd.time.values, format='%Y-%m-%d-%H:%M:%S')\n",
    "    gd['time'] = [cftime.datetime.strptime(tstr, '%Y-%m-%d-%H:%M:%S', calendar='julian') for tstr in gd.time.values]\n",
    "    GOES_dss[ii] = gd.sortby('time')\n",
    "print(GOES_dss[0])\n",
    "\n",
    "IM_ds = xr.open_mfdataset(os.path.join(IMROOT, '*.nc')) #single xr dataset\n",
    "#IM_ds['time'] = pd.to_datetime(IM_ds['time'].values)\n",
    "print(IM_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b1d6f2-a635-4b2a-b4c6-343dbfa7cb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8489495\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(GOES_dss[0].rad_vecs.values).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e7018-1111-4155-9ed1-519ae4f0608d",
   "metadata": {},
   "source": [
    "## NaN removal and normalization helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "669e3f2f-bec9-4d85-8482-7297bb24add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_nans(np_ar):\n",
    "    if np.isnan(np_ar).any():\n",
    "        valid_mask = ~np.isnan(np_ar)\n",
    "        nan_mask = np.isnan(np_ar)\n",
    "\n",
    "        # Create the grid for interpolation\n",
    "        x, y = np.meshgrid(np.arange(np_ar.shape[1]), np.arange(np_ar.shape[0]))\n",
    "\n",
    "        # Use griddata for interpolation of the NaN values using valid data\n",
    "        interpolated_data = griddata(\n",
    "            points=(x[valid_mask], y[valid_mask]),\n",
    "            values=np_ar[valid_mask],\n",
    "            xi=(x[nan_mask], y[nan_mask]),\n",
    "            method='nearest'\n",
    "        )\n",
    "\n",
    "        return interpolated_data\n",
    "    return np_ar\n",
    "\n",
    "def IMERG_lognorm(np_ar):\n",
    "    log_ar = np.log(np_ar + peps)\n",
    "    ar_log_norm = (log_ar - np.min(log_ar)) / (np.max(log_ar) - np.min(log_ar))\n",
    "    return ar_log_norm, np.min(log_ar), np.max(log_ar)\n",
    "\n",
    "def GOES_stdnorm(np_ar):\n",
    "    zz = (np_ar - np.nanmean(np_ar)) / np.nanstd(np_ar)\n",
    "    zz = np.nan_to_num(zz)\n",
    "    return zz, np.nanmean(np_ar), np.nanstd(np_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b17bb05-9c8d-4fda-8481-8cb766a3dc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "C08 2.75794 0.812074\n",
      "1\n",
      "C09 7.6557474 2.237307\n",
      "2\n",
      "C10 13.370373 3.9030612\n",
      "3\n",
      "C13 75.89942 24.088097\n"
     ]
    }
   ],
   "source": [
    "for ii, gd in enumerate(GOES_dss):\n",
    "    print(ii)\n",
    "    #GOES_dss[ii]['rad_vecs'] = interp_nans(gd.rad_vecs.values)\n",
    "    da, mm, ss = GOES_stdnorm(gd.rad_vecs)#.values)\n",
    "    da = xr.DataArray(da, dims=gd.dims, coords=gd.coords)\n",
    "    GOES_dss[ii]['rad_vecs'] = da\n",
    "    print(CHS[ii] % '', mm, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "953eafd4-2308-4ea1-84d3-412297697c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'pmmhr' ()> Size: 4B\n",
      "dask.array<_nanmin_skip-aggregate, shape=(), dtype=float32, chunksize=(), chunktype=numpy.ndarray> <xarray.DataArray 'pmmhr' ()> Size: 4B\n",
      "dask.array<_nanmax_skip-aggregate, shape=(), dtype=float32, chunksize=(), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "da, mn, mx = IMERG_lognorm(IM_ds['pmmhr'])\n",
    "da = xr.DataArray(da, dims=IM_ds.dims, coords=IM_ds.coords)\n",
    "IM_ds['pmmhr'] = da\n",
    "print(mn, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2380d9f4-c029-4ead-9793-0e670596c9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-9.2103405 4.5992537\n"
     ]
    }
   ],
   "source": [
    "print(mn.values, mx.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6225bb0e-3f6e-4d96-946e-b6015336ecb7",
   "metadata": {},
   "source": [
    "## Match IMERG and GOES timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99bfd1a1-0e4d-4ebe-9c21-e01090a78946",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<xarray.DataArray 'time' (time: 13022)> Size: 104kB\n",
       "  array([cftime.datetime(2018, 1, 1, 0, 26, 20, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 1, 1, 0, 56, 20, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 1, 1, 1, 26, 20, 0, calendar='julian', has_year_zero=False),\n",
       "         ...,\n",
       "         cftime.datetime(2018, 9, 30, 22, 56, 18, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 9, 30, 23, 26, 18, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 9, 30, 23, 56, 18, 0, calendar='julian', has_year_zero=False)],\n",
       "        dtype=object)\n",
       "  Coordinates:\n",
       "    * time     (time) object 104kB 2018-01-01 00:26:20 ... 2018-09-30 23:56:18,\n",
       "  <xarray.DataArray 'time' (time: 13022)> Size: 104kB\n",
       "  array([cftime.datetime(2018, 1, 1, 0, 26, 22, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 1, 1, 0, 56, 21, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 1, 1, 1, 26, 22, 0, calendar='julian', has_year_zero=False),\n",
       "         ...,\n",
       "         cftime.datetime(2018, 9, 30, 22, 56, 20, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 9, 30, 23, 26, 19, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 9, 30, 23, 56, 19, 0, calendar='julian', has_year_zero=False)],\n",
       "        dtype=object)\n",
       "  Coordinates:\n",
       "    * time     (time) object 104kB 2018-01-01 00:26:22 ... 2018-09-30 23:56:19,\n",
       "  <xarray.DataArray 'time' (time: 13022)> Size: 104kB\n",
       "  array([cftime.datetime(2018, 1, 1, 0, 26, 22, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 1, 1, 0, 56, 22, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 1, 1, 1, 26, 21, 0, calendar='julian', has_year_zero=False),\n",
       "         ...,\n",
       "         cftime.datetime(2018, 9, 30, 22, 56, 19, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 9, 30, 23, 26, 19, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 9, 30, 23, 56, 19, 0, calendar='julian', has_year_zero=False)],\n",
       "        dtype=object)\n",
       "  Coordinates:\n",
       "    * time     (time) object 104kB 2018-01-01 00:26:22 ... 2018-09-30 23:56:19,\n",
       "  <xarray.DataArray 'time' (time: 13022)> Size: 104kB\n",
       "  array([cftime.datetime(2018, 1, 1, 0, 26, 23, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 1, 1, 0, 56, 22, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 1, 1, 1, 26, 22, 0, calendar='julian', has_year_zero=False),\n",
       "         ...,\n",
       "         cftime.datetime(2018, 9, 30, 22, 56, 19, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 9, 30, 23, 26, 19, 0, calendar='julian', has_year_zero=False),\n",
       "         cftime.datetime(2018, 9, 30, 23, 56, 20, 0, calendar='julian', has_year_zero=False)],\n",
       "        dtype=object)\n",
       "  Coordinates:\n",
       "    * time     (time) object 104kB 2018-01-01 00:26:23 ... 2018-09-30 23:56:20],\n",
       " <xarray.DataArray 'time' (time: 13022)> Size: 104kB\n",
       " array([cftime.DatetimeJulian(2018, 1, 1, 0, 30, 0, 0, has_year_zero=False),\n",
       "        cftime.DatetimeJulian(2018, 1, 1, 1, 0, 0, 0, has_year_zero=False),\n",
       "        cftime.DatetimeJulian(2018, 1, 1, 1, 30, 0, 0, has_year_zero=False),\n",
       "        ...,\n",
       "        cftime.DatetimeJulian(2018, 9, 30, 23, 0, 0, 0, has_year_zero=False),\n",
       "        cftime.DatetimeJulian(2018, 9, 30, 23, 30, 0, 0, has_year_zero=False),\n",
       "        cftime.DatetimeJulian(2018, 9, 30, 23, 30, 0, 0, has_year_zero=False)],\n",
       "       dtype=object)\n",
       " Coordinates:\n",
       "   * time     (time) object 104kB 2018-01-01 00:30:00 ... 2018-09-30 23:30:00)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ii, gd in enumerate(GOES_dss):\n",
    "    minutes = gd.time.dt.minute\n",
    "    min_mask = ((minutes >= 25) & (minutes <= 34)) | (minutes >= 55) | (minutes <= 4)\n",
    "    GOES_dss[ii] = gd.where(min_mask, drop=True).drop_duplicates('time')\n",
    "\n",
    "fewest = np.argmin([gd.time.shape[0] for gd in GOES_dss]) #which dataset has the fewest timestamps?\n",
    "few_times = GOES_dss[fewest].time\n",
    "GOES_dss = [gd.sel(time=few_times, method='nearest') for gd in GOES_dss]\n",
    "IM_ds = IM_ds.sel(time=few_times, method='nearest')\n",
    "[gd.time for gd in GOES_dss], IM_ds.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3097cb-4d5c-43c1-b3c3-6a6d95598a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<xarray.Dataset> Size: 5GB\n",
       " Dimensions:   (time: 13022, len: 97714)\n",
       " Coordinates:\n",
       "   * time      (time) object 104kB 2018-01-01 00:26:20 ... 2018-09-30 23:56:18\n",
       "   * len       (len) int64 782kB 0 1 2 3 4 5 ... 97709 97710 97711 97712 97713\n",
       " Data variables:\n",
       "     rad_vecs  (time, len) float32 5GB -1.302 -1.118 -1.669 ... -0.6632 -0.3657\n",
       " Attributes:\n",
       "     description:  ABI radiance vectors,\n",
       " <xarray.Dataset> Size: 5GB\n",
       " Dimensions:   (time: 13022, len: 97714)\n",
       " Coordinates:\n",
       "   * time      (time) object 104kB 2018-01-01 00:26:22 ... 2018-09-30 23:56:19\n",
       "   * len       (len) int64 782kB 0 1 2 3 4 5 ... 97709 97710 97711 97712 97713\n",
       " Data variables:\n",
       "     rad_vecs  (time, len) float32 5GB -1.483 -1.1 -1.755 ... -0.7778 -0.4252\n",
       " Attributes:\n",
       "     description:  ABI radiance vectors,\n",
       " <xarray.Dataset> Size: 5GB\n",
       " Dimensions:   (time: 13022, len: 97714)\n",
       " Coordinates:\n",
       "   * time      (time) object 104kB 2018-01-01 00:26:22 ... 2018-09-30 23:56:19\n",
       "   * len       (len) int64 782kB 0 1 2 3 4 5 ... 97709 97710 97711 97712 97713\n",
       " Data variables:\n",
       "     rad_vecs  (time, len) float32 5GB -1.796 -1.262 -1.95 ... -0.7284 -0.3022\n",
       " Attributes:\n",
       "     description:  ABI radiance vectors,\n",
       " <xarray.Dataset> Size: 5GB\n",
       " Dimensions:   (time: 13022, len: 97714)\n",
       " Coordinates:\n",
       "   * time      (time) object 104kB 2018-01-01 00:26:23 ... 2018-09-30 23:56:20\n",
       "   * len       (len) int64 782kB 0 1 2 3 4 5 ... 97709 97710 97711 97712 97713\n",
       " Data variables:\n",
       "     rad_vecs  (time, len) float32 5GB -1.778 -0.6487 -1.942 ... -0.3336 0.1885\n",
       " Attributes:\n",
       "     description:  ABI radiance vectors]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GOES_dss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05516e-de78-47ae-9ca1-e652a5997429",
   "metadata": {},
   "source": [
    "# Build the MLP model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfd5a113-aefb-4da2-b90e-99563ca66ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim, shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.shape = shape\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "          layers.Flatten(), # 64k\n",
    "          layers.Dense(latent_dim*8, activation='swish'), # 64k -> latent_dim*8\n",
    "          layers.Dense(latent_dim, activation='swish'), # latent_dim*8 -> laten_dim\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "          layers.Dense(latent_dim*8, activation='swish'), # latent_dim -> latent_dim*8\n",
    "          layers.Dense(tf.math.reduce_prod(shape).numpy()), # latent_dim*8 -> vector w/o activation\n",
    "          layers.Reshape(shape)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "class MLPnolag(Model):\n",
    "    def __init__(self, enc_paths, latent_dim, out_dim):\n",
    "        super(MLPnolag, self).__init__()\n",
    "        self.encs = [Autoencoder(LD, [INDIM[ii]]) for ii in range(len(enc_paths))]#[load_model(pt) for pt in enc_paths]\n",
    "        #print(self.encs)\n",
    "        [en.predict(np.zeros(INDIM[ii])) for ii, en in enumerate(self.encs)]\n",
    "        [en.load_weights(enc_paths[ii]) for ii, en in enumerate(self.encs)]\n",
    "        self.mlp = tf.keras.Sequential([\n",
    "                layers.Flatten(), # 64k\n",
    "                layers.Dense(latent_dim*20, activation='swish'),\n",
    "                layers.Dense(latent_dim*5, activation='swish'),\n",
    "                layers.Dense(latent_dim, activation='swish'),\n",
    "                layers.Dense(tf.math.reduce_prod(out_dim).numpy()),\n",
    "                layers.Reshape(out_dim)\n",
    "        ])\n",
    "\n",
    "    #inputs should be a list of vectors [(97714, ), ..., (39125, )]\n",
    "    def call(self, inputs):\n",
    "        latents = [en(inputs[ii]) for ii, en in enumerate(self.encs)]\n",
    "        return self.mlp(latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073432c-3762-4e00-bb7d-1b0b3436dd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3054/3054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 11ms/step\n",
      "\u001b[1m 866/3054\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:31\u001b[0m 42ms/step"
     ]
    }
   ],
   "source": [
    "testnn = MLPnolag(WTF, LD, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07158c9-d3e2-4bee-bc8f-523bc96a01e2",
   "metadata": {},
   "source": [
    "# Setup data feeding to MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d81f9d-5895-4c3a-8a60-b16286ce8f6e",
   "metadata": {},
   "source": [
    "# Old stuff below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e397d2d9-05ee-42fd-87c9-9d3425d2b897",
   "metadata": {},
   "source": [
    "# _________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2591876707bf1db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:49:23.853690300Z",
     "start_time": "2024-12-05T23:49:17.207352500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "CMROOT = r\"C:\\Users\\axt5780\\OneDrive - The Pennsylvania State University\\PIML_project\\IMERG_vectors\"\n",
    "CMROOT = '/glade/work/jpan/IMERG_vecs/'\n",
    "nc_files = glob.glob(os.path.join(CMROOT, \"*.nc\"))\n",
    "\n",
    "all_data = []\n",
    "for nc_file in nc_files:\n",
    "    channel_vec = netCDF4.Dataset(nc_file)\n",
    "    data = channel_vec['pmmhr'][:, :]\n",
    "    \n",
    "    if np.isnan(data).any():\n",
    "        valid_mask = ~np.isnan(data)\n",
    "        nan_mask = np.isnan(data)  \n",
    "        \n",
    "        x, y = np.meshgrid(np.arange(data.shape[1]), np.arange(data.shape[0]))\n",
    "      \n",
    "        interpolated_data = griddata(\n",
    "              points=(x[valid_mask], y[valid_mask]),\n",
    "              values=data[valid_mask],\n",
    "              xi=(x[nan_mask], y[nan_mask]),\n",
    "              method='linear'\n",
    "        )\n",
    "        \n",
    "        data[nan_mask] = interpolated_data\n",
    "        \n",
    "    all_data.append(data)\n",
    "    channel_vec.close()\n",
    "    \n",
    "train = np.concatenate(all_data, axis=0)\n",
    "\n",
    "print(\"Combined data shape:\", train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447fb120-381f-49e7-ae1f-0acd78fa42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_tr = np.log(train + EPS)\n",
    "tr_log_norm = (log_tr - np.min(log_tr)) / (np.max(log_tr) - np.min(log_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0573d9-d533-4f5f-9a16-2c28843ae329",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_log_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186531811dab7bbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T23:49:24.768347200Z",
     "start_time": "2024-12-05T23:49:24.750429400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "  '''def __init__(self, latent_dim, shape):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.shape = shape\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='sigmoid'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(tf.math.reduce_prod(shape).numpy(), activation='sigmoid'),\n",
    "      layers.Reshape(shape)\n",
    "    ])'''\n",
    "\n",
    "  def __init__(self, latent_dim, shape):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.shape = shape\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(), # 64k\n",
    "      layers.Dense(latent_dim*8, activation='swish'), # 64k -> latent_dim*8\n",
    "      layers.Dense(latent_dim, activation='swish'), # latent_dim*8 -> laten_dim\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(latent_dim*8, activation='swish'), # latent_dim -> latent_dim*8\n",
    "      layers.Dense(tf.math.reduce_prod(shape).numpy()), # latent_dim*8 -> vector w/o activation\n",
    "      layers.Reshape(shape)\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56a386fa6a9b21f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:08:51.947894600Z",
     "start_time": "2024-12-06T00:08:51.937531900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "shape = train.shape[1:]\n",
    "latent_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07d460024e1b750",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:15:22.442294300Z",
     "start_time": "2024-12-06T00:08:55.637252600Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(latent_dim, shape)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "history = autoencoder.fit(tr_log_norm, tr_log_norm,\n",
    "              epochs=50,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdffd5167c695bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:16:25.931490300Z",
     "start_time": "2024-12-06T00:16:25.778629800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8dce812eb7f4b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:16:30.275429500Z",
     "start_time": "2024-12-06T00:16:30.226892400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "autoencoder.save_weights(f'weights/IMERG_{latent_dim}_downsample_log.weights.h5')\n",
    "print(\"Weights saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d449ee70a05966",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## REOPENING THE MODEL WITH WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe5595916f4ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T00:16:33.723157700Z",
     "start_time": "2024-12-06T00:16:32.952444300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ae1 = Autoencoder(latent_dim, shape) \n",
    "ae1.predict(tr_log_norm)\n",
    "ae1.load_weights(f'weights/IMERG_{latent_dim}_downsample_log.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73048822-f7d4-42a3-9fe1-9adea0a17c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ae1.weights[ii] - autoencoder.weights[ii] for ii in range(len(ae1.weights))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fcf05e-9074-4f79-b0b1-410ada761ed0",
   "metadata": {},
   "source": [
    "#### Loaded weights of the new model match the weights of the original model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ea3a8d-d386-4ae4-95f8-791d7d02a4de",
   "metadata": {},
   "source": [
    "# Check whether the distribution of encoded data matches original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6db940-0bf3-4ac8-9b0b-30ba18fde45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:, ::100].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528d2a7d-c0c2-4cc1-9a5b-3e527983afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c246c1-9869-46e1-a9f7-4745e262e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train[::1000, ::100].ravel(), bins=10**np.arange(-3, 2, 0.5))\n",
    "plt.xscale('log')\n",
    "plt.ylim(0, 150)\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('p rate [mm/h]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2a064-3325-40b9-aed8-268673c78798",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log_norm = ae1.predict(tr_log_norm[::1000])\n",
    "log_pred = pred_log_norm * (np.max(log_tr) - np.min(log_tr)) + np.min(log_tr)\n",
    "pred = np.exp(log_pred) - EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c6a77a-772a-487c-bb89-fa59a5ee0b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pred[:, ::100].ravel(), bins=10**np.arange(-3, 2, 0.5))\n",
    "plt.xscale('log')\n",
    "plt.ylim(0, 150)\n",
    "plt.ylabel('count')\n",
    "plt.xlabel('p rate [mm/h]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eadd701-e898-4d44-8faa-106c20793bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred[:, ::100] < EPS).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f6f909-b74a-43c9-81c5-060aebd643bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train[::1000, ::100] < EPS).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810130f-bb90-4a6b-9cf0-ad92883648db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-IST597tf]",
   "language": "python",
   "name": "conda-env-miniconda3-IST597tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
